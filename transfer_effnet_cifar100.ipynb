{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6124,"sourceType":"modelInstanceVersion","modelInstanceId":4599}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf \nimport keras_cv\nfrom tensorflow import keras \nfrom keras import layers, Input\n\n  \nimport numpy as np \nimport matplotlib.pyplot as plt \n  \n\n\n# Load in the data \ncifar100 = tf.keras.datasets.cifar100 \n\n# Distribute it to train and test set \n(x_train, y_train), (x_test, y_test) = cifar100.load_data() \nprint(x_train.shape, y_train.shape, x_test.shape, y_test.shape) \n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:36:08.592154Z","iopub.execute_input":"2024-04-17T12:36:08.593181Z","iopub.status.idle":"2024-04-17T12:36:35.422838Z","shell.execute_reply.started":"2024-04-17T12:36:08.593142Z","shell.execute_reply":"2024-04-17T12:36:35.421743Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-17 12:36:10.402231: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-17 12:36:10.402359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-17 12:36:10.553206: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([ \nlayers.Conv2D(16, (3, 3), activation='gelu',input_shape=(32, 32, 3), padding='same'), \nlayers.MaxPooling2D(2, 2), \nlayers.Conv2D(32, (3, 3),activation='gelu', padding='same'), \nlayers.MaxPooling2D(2, 2), \nlayers.Conv2D(64, (3, 3), activation='gelu', padding='same'), \nlayers.MaxPooling2D(2, 2), \nlayers.Conv2D(128, (3, 3), activation='gelu', padding='same'), \n\n\nlayers.Flatten(), \nlayers.Dense(256, activation='gelu'), \nlayers.BatchNormalization(), \nlayers.Dense(256, activation='gelu'), \nlayers.Dropout(0.3), \nlayers.BatchNormalization(), \nlayers.Dense(100, activation='gelu') \n]) \n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, AveragePooling2D\nfrom tensorflow.keras.layers import Add, DepthwiseConv2D, Resizing\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\ndef inverted_residual_block(x, lf, expand=64, squeeze=16):\n  m = Conv2D(expand, (1,1), activation='gelu', padding= \"same\")(x)\n  m = DepthwiseConv2D(lf, activation='gelu', padding= \"same\")(m)\n  m = Conv2D(squeeze, (1,1), activation='gelu', padding= \"same\")(m)\n  return Add()([m, x])\n\ninput_img = Input(shape=(32,32,3))\n\n#shortcut 1\nx_short1 = Conv2D(32, kernel_size=(3,3), padding= \"same\", activation='gelu')(input_img)\nx_short1 = Resizing(8, 8, interpolation=\"bilinear\", crop_to_aspect_ratio=True)(x_short1)\n\nx = layers.Conv2D(16, (3, 3), activation='gelu',input_shape=(32, 32, 3), padding='same')(input_img)\nx = inverted_residual_block(x, (3,3), expand=64, squeeze=16) #mobilenet layer\nx = layers.MaxPooling2D(2, 2)(x)\nx = layers.Conv2D(32, (3, 3),activation='gelu', padding='same')(x) \nx = inverted_residual_block(x, (3,3), expand=64, squeeze=32) #mobilenet layer\nx = layers.MaxPooling2D(2, 2)(x)\n\nx = Add()([x, x_short1])\n\nx = layers.Conv2D(64, (3, 3), activation='gelu', padding='same')(x)\nx = inverted_residual_block(x, (3,3), expand=128, squeeze=64) #mobilenet layer\nx = layers.MaxPooling2D(2, 2)(x)\n\n#shortcut 2\nx_short2 = Conv2D(128, kernel_size=(3,3), padding= \"same\", activation='gelu')(input_img)\nx_short2 = Resizing(4, 4, interpolation=\"bilinear\", crop_to_aspect_ratio=True)(x_short2)\n\nx = layers.Conv2D(128, (3, 3), activation='gelu', padding='same')(x) \nx = inverted_residual_block(x, (3,3), expand=192, squeeze=128) #mobilenet layer\n\nx = Add()([x, x_short2])\n\nx = layers.Conv2D(128, (3, 3), activation='gelu', padding='same')(x) \nx = inverted_residual_block(x, (3,3), expand=192, squeeze=128) #mobilenet layer\n\nx = layers.Flatten()(x) \nx = layers.Dense(256, activation='gelu')(x) \nx = layers.BatchNormalization()(x)\nx = layers.Dense(256, activation='gelu')(x) \nx = layers.Dropout(0.3)(x)\nx = layers.BatchNormalization()(x)\noutput = layers.Dense(100, activation='gelu')(x)\n\n\nmodel = Model(inputs=input_img, outputs=[output])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# number of classes\nnb_classes = len(np.unique(y_train))\n\n# convert class vectors to binary class matrices\ny_train = to_categorical(y_train, nb_classes)\ny_test = to_categorical(y_test, nb_classes)\n\n# Normalize data\n#med_train = np.mean(x_train)\n#std_train  = np.std(x_train)\n#med_test = np.mean(x_test)\n#std_test  = np.std(x_test)\n\n#x_train = (x_train - med_train) / std_train\n#x_test = (x_test - med_test) / std_test\n\n#x_train =(x_train)/255.0\nx_test = (x_test)/255\n\n\ntrain_datagen = ImageDataGenerator(\n        #rotation_range= 40,\n        rescale=1./255,\n        vertical_flip=True,\n        horizontal_flip=True)\n\n\nit = train_datagen.flow(x_train, y_train, shuffle=False)\nprint(x_train.shape)\nprint(y_train.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:36:35.425106Z","iopub.execute_input":"2024-04-17T12:36:35.426265Z","iopub.status.idle":"2024-04-17T12:36:35.735655Z","shell.execute_reply.started":"2024-04-17T12:36:35.426234Z","shell.execute_reply":"2024-04-17T12:36:35.734580Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(50000, 32, 32, 3)\n(50000, 100)\n","output_type":"stream"}]},{"cell_type":"code","source":"print (np.max(x_train), np.min(x_train))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:36:35.737762Z","iopub.execute_input":"2024-04-17T12:36:35.738086Z","iopub.status.idle":"2024-04-17T12:36:35.775575Z","shell.execute_reply.started":"2024-04-17T12:36:35.738061Z","shell.execute_reply":"2024-04-17T12:36:35.774532Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"255 0\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nimport tensorflow_hub as hub\n\nmodel_eff = keras_cv.models.EfficientNetV2Backbone.from_preset(\n   \"efficientnetv2_s_imagenet\"#\"efficientnetv2_b2_imagenet\",\n)\n\n# model_eff.trainable = False\n\nmodel_convnext = keras.applications.ConvNeXtTiny(\n    model_name=\"convnext_tiny\",\n    include_top=None,\n    #include_preprocessing=True,\n    weights=\"imagenet\",\n    input_tensor=None,\n    #input_shape=(32,32,3),\n    pooling=None,\n    #classes=100,\n    #classifier_activation=\"softmax\",\n)\n\ninput_img = Input(shape=(32,32,3))\n\nx = model_eff(input_img)\n#x = model_convnext(input_img)\n#x = layers.GlobalAveragePooling2D()(x)\nx = layers.Flatten()(x)\nx = layers.Dense(512, activation='gelu')(x) \nx = layers.Dropout(0.3)(x)\nx = layers.BatchNormalization()(x)\noutput = layers.Dense(100, activation='softmax')(x)\n\nmodel = Model(inputs=input_img, outputs=[output])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:36:40.208571Z","iopub.execute_input":"2024-04-17T12:36:40.208972Z","iopub.status.idle":"2024-04-17T12:36:56.875528Z","shell.execute_reply.started":"2024-04-17T12:36:40.208941Z","shell.execute_reply":"2024-04-17T12:36:56.874448Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/efficientnetv2/keras/efficientnetv2_s_imagenet/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/efficientnetv2/keras/efficientnetv2_s_imagenet/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/efficientnetv2/keras/efficientnetv2_s_imagenet/2' to your Kaggle notebook...\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_tiny_notop.h5\n\u001b[1m111650432/111650432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficient_net_v2s_backbone      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │    \u001b[38;5;34m20,331,360\u001b[0m │\n│ (\u001b[38;5;33mEfficientNetV2Backbone\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m655,872\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m51,300\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficient_net_v2s_backbone      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EfficientNetV2Backbone</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,040,580\u001b[0m (80.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,040,580</span> (80.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,885,684\u001b[0m (79.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,885,684</span> (79.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m154,896\u001b[0m (605.06 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,896</span> (605.06 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=1e-7)\n\nmodel.compile( \nloss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), \n#optimizer= keras.optimizers.Adam(learning_rate=1e-4),\noptimizer= keras.optimizers.Lion(learning_rate=1e-4),\nmetrics=['accuracy']\n) \n\n\nhist = model.fit(it,\n                 epochs=30, \n                 batch_size=128, \n                 verbose=1,\n                 callbacks=[reduce_lr],\n                 validation_data=(x_test, y_test)) ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:37:03.088959Z","iopub.execute_input":"2024-04-17T12:37:03.090139Z","iopub.status.idle":"2024-04-17T13:26:01.153501Z","shell.execute_reply.started":"2024-04-17T12:37:03.090105Z","shell.execute_reply":"2024-04-17T13:26:01.152417Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713357626.584878      85 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 155ms/step - accuracy: 0.1054 - loss: 4.2367 - val_accuracy: 0.3692 - val_loss: 2.4111 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.3509 - loss: 2.5004 - val_accuracy: 0.4790 - val_loss: 1.8818 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.4608 - loss: 1.9795 - val_accuracy: 0.5341 - val_loss: 1.6809 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.5320 - loss: 1.7044 - val_accuracy: 0.5665 - val_loss: 1.5838 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - accuracy: 0.5776 - loss: 1.4915 - val_accuracy: 0.5861 - val_loss: 1.5579 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 55ms/step - accuracy: 0.6199 - loss: 1.3244 - val_accuracy: 0.5939 - val_loss: 1.5167 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.6587 - loss: 1.1758 - val_accuracy: 0.6076 - val_loss: 1.4819 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - accuracy: 0.6857 - loss: 1.0668 - val_accuracy: 0.6111 - val_loss: 1.5580 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.7155 - loss: 0.9669 - val_accuracy: 0.6142 - val_loss: 1.5326 - learning_rate: 1.0000e-04\nEpoch 10/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.7421 - loss: 0.8591 - val_accuracy: 0.6122 - val_loss: 1.6200 - learning_rate: 1.0000e-04\nEpoch 11/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 54ms/step - accuracy: 0.7998 - loss: 0.6593 - val_accuracy: 0.6409 - val_loss: 1.5172 - learning_rate: 2.0000e-05\nEpoch 12/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.8456 - loss: 0.5019 - val_accuracy: 0.6490 - val_loss: 1.5031 - learning_rate: 2.0000e-05\nEpoch 13/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.8692 - loss: 0.4242 - val_accuracy: 0.6487 - val_loss: 1.5495 - learning_rate: 2.0000e-05\nEpoch 14/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.8895 - loss: 0.3660 - val_accuracy: 0.6539 - val_loss: 1.5345 - learning_rate: 4.0000e-06\nEpoch 15/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 55ms/step - accuracy: 0.8977 - loss: 0.3349 - val_accuracy: 0.6535 - val_loss: 1.5534 - learning_rate: 4.0000e-06\nEpoch 16/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.9012 - loss: 0.3267 - val_accuracy: 0.6538 - val_loss: 1.5630 - learning_rate: 4.0000e-06\nEpoch 17/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - accuracy: 0.9074 - loss: 0.3092 - val_accuracy: 0.6551 - val_loss: 1.5483 - learning_rate: 8.0000e-07\nEpoch 18/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 53ms/step - accuracy: 0.9029 - loss: 0.3133 - val_accuracy: 0.6523 - val_loss: 1.5755 - learning_rate: 8.0000e-07\nEpoch 19/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.9037 - loss: 0.3144 - val_accuracy: 0.6558 - val_loss: 1.5593 - learning_rate: 8.0000e-07\nEpoch 20/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.9085 - loss: 0.3016 - val_accuracy: 0.6549 - val_loss: 1.5560 - learning_rate: 1.6000e-07\nEpoch 21/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.9094 - loss: 0.3021 - val_accuracy: 0.6506 - val_loss: 1.5816 - learning_rate: 1.6000e-07\nEpoch 22/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.9117 - loss: 0.2940 - val_accuracy: 0.6531 - val_loss: 1.5946 - learning_rate: 1.6000e-07\nEpoch 23/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.9083 - loss: 0.3000 - val_accuracy: 0.6555 - val_loss: 1.5797 - learning_rate: 1.0000e-07\nEpoch 24/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.9098 - loss: 0.2949 - val_accuracy: 0.6544 - val_loss: 1.5753 - learning_rate: 1.0000e-07\nEpoch 25/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.9108 - loss: 0.2919 - val_accuracy: 0.6581 - val_loss: 1.5480 - learning_rate: 1.0000e-07\nEpoch 26/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - accuracy: 0.9063 - loss: 0.3059 - val_accuracy: 0.6551 - val_loss: 1.5594 - learning_rate: 1.0000e-07\nEpoch 27/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.9077 - loss: 0.3028 - val_accuracy: 0.6503 - val_loss: 1.5920 - learning_rate: 1.0000e-07\nEpoch 28/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.9098 - loss: 0.2976 - val_accuracy: 0.6521 - val_loss: 1.5794 - learning_rate: 1.0000e-07\nEpoch 29/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.9109 - loss: 0.3016 - val_accuracy: 0.6560 - val_loss: 1.5553 - learning_rate: 1.0000e-07\nEpoch 30/30\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - accuracy: 0.9088 - loss: 0.3001 - val_accuracy: 0.6548 - val_loss: 1.5515 - learning_rate: 1.0000e-07\n","output_type":"stream"}]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Error')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}